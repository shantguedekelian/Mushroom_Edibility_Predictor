{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ae4bee",
   "metadata": {},
   "source": [
    "# Doing all of the EDA and Model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51531a53",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5833960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4103, 0.3823, 0.8095],\n",
      "        [0.6915, 0.2055, 0.5150],\n",
      "        [0.8426, 0.7800, 0.6047],\n",
      "        [0.4650, 0.5369, 0.2615],\n",
      "        [0.9701, 0.6494, 0.3163]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train edible -> FOUND | ../data/mushrooms\\train\\edible\n",
      "train poisonous -> FOUND | ../data/mushrooms\\train\\poisonous\n",
      "val edible -> FOUND | ../data/mushrooms\\val\\edible\n",
      "val poisonous -> FOUND | ../data/mushrooms\\val\\poisonous\n",
      "test edible -> FOUND | ../data/mushrooms\\test\\edible\n",
      "test poisonous -> FOUND | ../data/mushrooms\\test\\poisonous\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"../data/mushrooms\"\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"edible\", \"poisonous\"]:\n",
    "        p = os.path.join(BASE_DIR, split, cls)\n",
    "        print(split, cls, \"->\", \"FOUND\" if os.path.exists(p) else \"MISSING\", \"|\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d74b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['edible', 'poisonous']\n",
      "Train size: 26886\n",
      "Val size: 8851\n",
      "Test size: 3831\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Basic transform (we'll improve this later)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "DATA_DIR = \"../data/mushrooms\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_dataset   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(f\"{DATA_DIR}/test\", transform=transform)\n",
    "\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size:\", len(val_dataset))\n",
    "print(\"Test size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77b22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch (train): 841\n",
      "Batches (val): 277\n",
      "Batches (test): 120\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(\"Batches per epoch (train):\", len(train_loader))\n",
    "print(\"Batches (val):\", len(val_loader))\n",
    "print(\"Batches (test):\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1352c529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([32, 3, 224, 224])\n",
      "Batch labels shape: torch.Size([32])\n",
      "Unique labels in batch: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(\"Batch images shape:\", images.shape)\n",
    "print(\"Batch labels shape:\", labels.shape)\n",
    "print(\"Unique labels in batch:\", labels.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "from torchvision.models import ResNet18_Weights\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Step 5 (also in roadmap): replace final layer for 2 classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457a83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: CrossEntropyLoss\n",
      "Optimizer: Adam lr = 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Loss:\", type(criterion).__name__)\n",
    "print(\"Optimizer:\", type(optimizer).__name__, \"lr =\", optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91797667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([32, 2])\n",
      "labels shape: torch.Size([32])\n",
      "example logits (first row): [-0.23532402515411377, -0.7915375828742981]\n"
     ]
    }
   ],
   "source": [
    "# Step 7A: one-batch forward pass sanity check (no training yet)\n",
    "\n",
    "model.train()  # training mode\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "\n",
    "print(\"outputs shape:\", outputs.shape)  # expect [batch_size, 2]\n",
    "print(\"labels shape:\", labels.shape)    # expect [batch_size]\n",
    "print(\"example logits (first row):\", outputs[0].detach().cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42baef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train loss 0.2036 acc 0.9134 | val loss 0.7614 acc 0.7519\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "# Run exactly 1 epoch first\n",
    "train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Epoch 1 | train loss {train_loss:.4f} acc {train_acc:.4f} | val loss {val_loss:.4f} acc {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d86073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to: checkpoints/resnet18_epoch1.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "checkpoint_path = \"checkpoints/resnet18_epoch1.pt\"\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"class_to_idx\": train_dataset.class_to_idx,\n",
    "    \"classes\": train_dataset.classes\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(\"Saved checkpoint to:\", checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb4d95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def run_validation(model, val_loader, criterion, device):\n",
    "    model.eval()                 # turn off dropout/batchnorm training behavior\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():        # disable gradient tracking\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = total_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a099ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7614\n",
      "Validation acc:  0.7519\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = run_validation(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Validation loss: {val_loss:.4f}\")\n",
    "print(f\"Validation acc:  {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
